
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>The Science of A/B Testing - DATa-ing</title>
  <meta name="author" content="Vikas Raturi">

  
  <meta name="description" content="Modern day web or mobile ecosystem thrive on data-driven decisions, based on data obtained from well-designed experiments. Lets take look at the &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://vikasrtr.github.io/science-of-a-b-testing/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="DATa-ing" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href='http://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>
<link href='http://fonts.googleapis.com/css?family=Fjalla+One' rel='stylesheet' type='text/css'>

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-65284289-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">DATa-ing</a></h1>
  
    <h2>Thoughts on Data & Science</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="sitesearch" value="vikasrtr.github.io">
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/about">About</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">The Science of A/B Testing</h1>
    
    
      <p class="meta">
        




01 Sep 2015
        
      </p>
    
  </header>


<div class="entry-content"><p>Modern day web or mobile ecosystem thrive on data-driven decisions, based on data obtained from <em>well-designed</em> <strong>experiments</strong>. Lets take look at the science, behind one of the most popular experiments on web - <strong>A/B Tests</strong>.</p>

<!--more-->


<p>This post is part of a series about A/B tests.
I will post the links as i write the subsequent posts.</p>

<script
    src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML,http://vikasrtr.github.io/javascripts/MathJaxLocal.js'>
</script>


<h2>What is A/B testing</h2>

<blockquote><p>A/B testing or split testing is a randomized experiment, which compares performance of a metric, over alternate versions of same web page, simultaneously.</p></blockquote>

<p>Simply, in A/B testing, different users are shown different variants of same web page and performance of a given metric, say <em>clicking a button</em>, is compared. How we select the users and how measure such a performance is key to successful test.</p>

<h1></h1>

<p>To understand A/B test, lets break-through the definition one-by-one:</p>

<blockquote><p><strong>a randomized experiment</strong></p></blockquote>

<p>What is a randomized experiment and why do we need it ?<br/>
A randomized experiment refers to an experiment in which the subjects or objects are <code>selected</code> in randomized fashion. This is done, so that the process of selection represents a <code>chance model</code> and any <code>bias</code> is reduced.</p>

<blockquote><p><strong>performance of a metric</strong></p></blockquote>

<p>A metric connects the maths to business.<br/>
A metric can be any business query, that the test seeks to be answered. For example, <em>does the new search box works?</em> or <em>does changing color of Buy button increase sales?</em></p>

<blockquote><p><strong>alternate versions of same page</strong></p></blockquote>

<p>A/B test <strong>must</strong> always be done on <strong>same page</strong> with <strong>slight</strong> variation. The slight variation scheme is used to eliminate the <code>confounding</code> variable, which may hide the cause of a particular result or action.
However, contextualizing the results of a test may sometimes bring wonderfully surprising results, as mentioned here at <a href="http://nerds.airbnb.com/experiments-at-airbnb/">airbnb&rsquo;s blog</a>.</p>

<blockquote><p><strong>simultaneously</strong></p></blockquote>

<p>This perhaps may be the most important characterisitc of A/B tests. The test must be performed for all subjects at same time. This is done to create a notion of independence among subjects of test.<br/>
For example, <em>running part of test on Sunday or other on Monday, will lead to biased results</em>.</p>

<h2>The Basics</h2>

<p>In A/B testing, the users of application, are first randomly selected and placed into several buckets or groups and then tested for result. The process can be sumarized as:</p>

<ul>
<li>Categorize visitors into groups</li>
<li>Provide variants of a web page to users of each groups, with all users of same group getting same variant.</li>
<li>Measure and compare the response</li>
</ul>


<h2>The Maths</h2>

<p>As theory of probabilistic development goes with gamblers, the statistical theory goes with, <strong>medical field of clinical trials</strong> and thus it borrows much of its conventions from there. For simplicity let us assume that we want to generate only two groups.</p>

<blockquote><p>In an A/B test, the incoming users are randomly placed into two groups.<br/>
One group is shown the <strong>current web page</strong> and another is shown a variant.</p></blockquote>

<p>The users shown the current page are called - <strong>Control Group</strong> and the users, which gets the variant are called - <strong>Treatment Group</strong>.</p>

<blockquote><p>The resaon for using control group is to have a baseline for comparing the result of variant.</p></blockquote>

<p>Statistically, A/B tests are simply <code>two-sample hypothesis tests</code>.</p>

<p><strong>What is hypothesis testing?</strong><br/>
A hypothesis is simply <em>a statement</em>, that hasn&rsquo;t been proved true. And hypothesis testing is <em>process of verifying that, whether a given hypothesis is true</em>.</p>

<p>Since, a hypothesis can be complex enough to deduce its probability, we use a different approach to prove our hypothesis, which is known as <strong>null-hypothesis testing</strong>. In null-hypothesis testing, we use a baseline claim called - <code>null hypothesis</code> and <em>try to reject</em> it based on comparison to another hypothesis called - <code>alternate hypothesis</code>.</p>

<blockquote><p>In A/B testing, null-hypothesis states that &ldquo;the variant has no effect on user&rdquo;, while alternate hypothesis states that &ldquo;the variant has <strong>significant</strong> effect on user!&rdquo;</p></blockquote>

<p>Mathematically,<br/>
$$H_o = p_c - p_t$$
where $H_o$ is the null-hypothesis &amp; $p_c$ and $p_t$ are rate of change of metric for control and treatment groups respectively.</p>

<p>To reject the null-hypothesis, we have to prove that:<br/>
$$H_o = p_c - p_t &lt; 0 $$
i.e. performance of metric is less in treatment group, than control group.</p>

<p><strong>But why we need these hypotheses things ?</strong><br/>
One common understanding is to think that $p_c - p_t$ is simply the required difference, so why need a hypothesis testing.<br/>
The answer is that we want to account for <em>chance variation</em>. Since, even if both groups are shown <strong>exactly same page</strong> (something called <em>dummy testing</em>), even then the rates will be different due to chance variation. And we don&rsquo;t want to be misleaded by chance, making sure that the results are due to actual difference.</p>

<p><strong>How to be confident: Two sample Z-test</strong><br/>
To account for chance variation, we use little stats and something called Z-test.<br/>
Z-test falls in domain of significance testing, allowing us to detect the <em>significance</em> of results as compared to null-hypothesis.</p>

<p>Simply, Z-score is:<br/>
$$ Z = \frac{\text{difference of rates}}{\text{Standard Error of sample}}$$
And the complete equation thus becomes,<br/>
$$Z = \frac{p_c - p_t}{\sqrt{\frac{p_c(1 - p_c)}{N_c} + \frac{p_t(1 - p_t)}{N_t}}}$$
Here, $N_c$ and $N_t$ are number of users in control and treatment groups respectively.</p>

<p><strong>But what actually is z-score</strong></p>

<blockquote><p>Z-score is the probability of obtaining a test-statisitc, as extreme as the observed one, assuming the null-hypothesis to be true. It is denoted by <strong>P</strong> and called as <strong>P-value</strong>.</p></blockquote>

<p>If P &lt; 0.05, then we conclude that the null-hypothesis is rejected, making the observed difference <em>statistically significant</em>, otherwise the observed difference is just due to chance variation.</p>

<p>In upcoming post we take a look at some data and code to perform an A/B experiment.</p>

<p>Stay Curious !!</p>

<h2>References</h2>

<ul>
<li><a href="http://20bits.com/article/statistical-analysis-and-ab-testing">http://20bits.com/article/statistical-analysis-and-ab-testing</a></li>
<li><a href="http://nerds.airbnb.com/experiments-at-airbnb/">http://nerds.airbnb.com/experiments-at-airbnb/</a></li>
</ul>

</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">Vikas Raturi</span></span>

      




01 Sep 2015
      

<span class="categories">
  
    <a class='category' href='/blog/topic/a-slash-b-testing/'>a/b testing</a>, <a class='category' href='/blog/topic/analytics/'>analytics</a>, <a class='category' href='/blog/topic/hypothesis-testing/'>hypothesis testing</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  <a href="//twitter.com/share" class="twitter-share-button" data-url="http://vikasrtr.github.io/science-of-a-b-testing/" data-via="vikas_rtr" data-counturl="http://vikasrtr.github.io/science-of-a-b-testing/" >Tweet</a>
  
  
  
    <div class="fb-like" data-send="true" data-width="450" data-show-faces="false"></div>
  
</div>

    
    <p class="meta">
      
      
    </p>
  </footer>
</article>

  <section>
    <h1>Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
  </section>

</div>

<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/science-of-a-b-testing/">The Science of A/B Testing</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating...</li>
  </ul>
  
  <a href="https://github.com/vikasrtr">@vikasrtr</a> on GitHub
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'vikasrtr',
            count: 0,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>



<section class="googleplus">
  <h1>
    <a href="https://plus.google.com/VikasRaturi?rel=author">
      <img src="http://www.google.com/images/icons/ui/gprofile_button-32.png" width="32" height="32">
      Google+
    </a>
  </h1>
</section>



  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2015 - Vikas Raturi -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'dataing';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://vikasrtr.github.io/science-of-a-b-testing/';
        var disqus_url = 'http://vikasrtr.github.io/science-of-a-b-testing/';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id; js.async = true;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>





  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
